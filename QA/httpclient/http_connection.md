**长短连接**

1. 从客户端发起一个HTTP请求到服务端响应HTTP请求之间，大致有以下几个步骤

![http request follow](http-request.png"HTTP请求流程")

* HTTP1.0 最早在网页中使用是 1996 年，那个时候只是使用一些较为简单的网页和网络的请求，**每次请求都需要建立一个单独的连接**，上一次和下一次请求完全分离。这种做法，即使每次的请求量都很小，但是客户端和服务端每次建立 TCP 连接和关闭 TCP 连接都是相对比较费时的过程，严重影响客户端和服务端的性能。

* 基于以上的问题，HTTP1.1 在 1999 年广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议（2015年诞生了 HTTP2，但是还未大规模应用），这里不详细对比 HTTP1.1 针对  HTTP1.0 改进了什么，只是在连接这块，**HTTP1.1 支持在一个 TCP 连接上传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗延迟**，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点，这就是长连接，HTTP1.1 默认使用长连接。
* **长短连接是通信层 TCP 的概念**，HTTP 是应用层协议，它只能说告诉通信层我打算一段时间内复用 TCP 通道而没有自己去建立、释放 TCP 通道的能力。那么 HTTP 是如何告诉通信层复用 TCP 通道的呢？看下图：

![http1.1 connection](http1.1-request.png"HTTP1.1 连接")

**步骤如下：**

1. 客户端发送一个 Connection: keep-alive的header，表示需要保持连接
2. 客户端可以顺带 Keep-Alive: timeout=5,max=100 这个 header 给服务端，表示 tcp 连接最多保持 5 秒，长连接接受 100 次请求就断开，不过浏览器看了一些请求貌似没看到带这个参数的
3. 服务端必须能识别 Connection: keep-alive 这个 header ，并且通过 Response Header 带同样的  Connection: keep-alive ，告诉客户端我可以保持连接
4. 客户端和服务端之间通过保持的通道收发数据
5. 最后一次请求数据，客户端带 Connection：close这个header ，表示连接关闭



**状态码:** 状态代码为3位数字。
1xx：指示信息–表示请求已接收，继续处理。
2xx：成功–表示请求已被成功接收、理解、接受。
3xx：重定向–要完成请求必须进行更进一步的操作。
4xx：客户端错误–请求有语法错误或请求无法实现。
5xx：服务器端错误–服务器未能实现合法的请求。




至此在一个通道上交换数据的过程结束，在默认的情况下：

- 长连接的请求数量限定是最多连续发送 100 个请求，超过限制即关闭这条连接
- 长连接连续两个请求之间的超时时间是 15 秒（存在1~2秒误差），超时后会关闭 TCP 连接，因此使用长连接应当尽量保持在 13 秒之内发送一个请求
- 这些的限制都是在重用长连接与长连接过多之间做的一个折衷，因为长连接虽好，但是长时间的TCP连接容易导致系统资源无效占用，浪费系统资源。

最后这个地方多说一句 http 的 keep-alive 和 tcp 的 keep-alive 的区别，一个经常讲的问题，顺便记录一下：

- http 的 keep-alive 是为了复用已有连接
- tcp 的 keep-alive 是为了保活，即保证对端还存活，不然对端已经不在了我这边还占着和对端的这个连接，浪费服务器资源，做法是隔一段时间发送一个心跳包到对端服务器，一旦长时间没有接收到应答，就主动关闭连接



**性能提升的原因**

通过前面的分析，很显而易见的，使用HTTP连接池提升性能最重要的原因就是省去了大量连接建立与释放的时间，除此之外还想说一点。

TCP建立连接的时候有如下流程：

![tcp connection](tcp-connect.png"TCP连接")

如图所示，这里面有两个队列，分别为 syns queue（半连接队列）与 accept queue（全连接队列）。

一旦不使用长连接而每次连接都重新握手的话，队列一满服务端将会发送一个 ECONNREFUSED 错误信息给到客户端，相当于这次请求就失效了，即使不失效，后来的请求需要等待前面的请求处理，排队也会增加响应的时间。

By the way，基于上面的分析，不仅仅是 HTTP，所有应用层协议，例如数据库有数据库连接池、hsf 提供了 hsf 接口连接池，使用连接池的方式对于接口性能都是有非常大的提升的，都是同一个道理。



**使用连接池的注意点**

使用连接池，切记每个任务的执行时间不要太长。

因为 HTTP 请求也好、数据库请求也好、hsf 请求也好都是有超时时间的，比如连接池中有 10 个线程，并发来了 100 个请求，一旦任务执行时间非常长，连接都被先来的 10 个任务占着，后面 90 个请求迟迟得不到连接去处理，就会导致这次的请求响应慢甚至超时。

当然每个任务的业务不一样，但是按照我的经验，尽量把任务的执行时间控制在 50ms 最多 100ms 之内，如果超出的，可以考虑以下三种方案：

- 优化任务执行逻辑，比如引入缓存
- 适当增大连接池中的连接数量
- 任务拆分，将任务拆分为若干小任务

**连接池中的连接数量如何设置**

首先我们需要明确一个点，连接池中的连接数量太多不好、太少也不好：

- 比如 qps=100，因为上游请求速率不可能是恒定不变的 100 个请求/秒，可能前 1 秒 900 个请求，后 9 秒 100 个请求，平均下来 qps=100，当连接数太多的时候，可能出现的场景是高流量下建立连接--->低流量下释放部分连接--->高流量下重新建立连接的情况，相当于虽然使用了连接池，但是因为流量不均匀反复建立连接、释放链接
- 线程数太少当然也是不好的，任务多而连接少，导致很多任务一直在排队等待前面的执行完才可以拿到连接去处理，降低了处理速度

那针对连接池中的连接数量如何设置的这个问题，答案是没有固定的，但是可以通过估算得到一个预估值。

首先开发同学对于一个任务每天的调用量心中需要有数，假设一天 1000W 次好了，线上有 10 台服务器，那么平均到每台服务器每天的调用量在 100W，100W 平均到 1 天的 86400 秒，每秒的调用量 1000000 / 86400 ≈ 11.574 次，根据接口的一个平均响应时长适当加一点余量，差不多设置在 15~30 比较合适，根据线上运行的实际情况再做调整。